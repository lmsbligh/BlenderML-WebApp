

## Rough Aims

- [x] Establish where I'm up to with the project
- [x] Write brief summary of achievements in doc
- [x] Fix GPU memory error in test functionality
- [ ] Finish implementing test functionality
- [ ] Come up with plans to test/train current model with current data set

## What I did

#### GPU Memory Errors (Training)

Investigating this: Receiving an error when running app.py, looks familiar but I can't remember exactly what caused it, tomorrow or Saturday I will attack this.

Error:
```
Traceback (most recent call last):
  File "c:\Users\liom1\Documents\projects\ML\blenderML\app.py", line 65, in <module>
    test(model, val_data_loader)
  File "c:\Users\liom1\Documents\projects\ML\blenderML\custom_nn\test.py", line 15, in test
    output = model(inputs)
  File "C:\ProgramData\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "c:\Users\liom1\Documents\projects\ML\blenderML\custom_nn\custom_nn.py", line 103, in forward
    x = self.conv_layers(x)
  File "C:\ProgramData\anaconda3\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\ProgramData\anaconda3\lib\site-packages\torch\nn\modules\container.py", line 217, in forward
    input = module(input)
    return forward_call(*args, **kwargs)
  File "C:\ProgramData\anaconda3\lib\site-packages\torch\nn\modules\conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\ProgramData\anaconda3\lib\site-packages\torch\nn\modules\conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 6.00 GiB total capacity; 11.45 GiB already allocated; 0 bytes free; 11.93 GiB reserved in total by PyT
```
The test function is listed below:

```python
def test(model, data_loader) -> list:

    """Runs a forward pass of the model then compares the

    result to the target. Returns a list of all outputs

    (predicted material parameters).

    """

    running_loss = 0.0

    outputs = []

    model.eval()

    for i, data in enumerate(data_loader, 0):

        # get the inputs; data is a list of [inputs, labels]

        inputs, label = data

        # forward

        output = model(inputs)

        loss = loss_function(output, label)

        outputs.append(output)

        running_loss += loss.item()

    print(f"{running_loss=}")

    print(f"{running_loss/len(data_loader)=}")

    return outputs
```
So far I've been trying to find out why I'm running out of GPU memory. I've tried:

 - Putting the output tensor on the CPU before adding it to the output list.
 - Investigated the size of both using the following f-string:
```python 
print(f"Current output: {i} size of output i: {sys.getsizeof(output)} cumulative size of all outputs: {sys.getsizeof(outputs)}")
```
The last output before the program ran out of GPU Memory was the following:
```
Current output: 255 size of output i: 72 cumulative size of all outputs: 2200
```
Which implies that the output is not responsible as it is only using 2200bytes of memory.

After some Googling and experimentation, I found using the following to fix the issue:

```python
with torch.no_grad():
	for . . . :
		. . . 
```

### Test Functionality

The test function is lacking the following necessary functionality:

Allow us to test a small batch of images, returning both the images and the predicted props so that we can then render those predicted props. Currently it only returns the predicted props.

After further research into how PyTorch works it seems the best way to achieve this is to define custom datasets that are subsets of the validation and pass that into the training function. Or I could pass the whole DataSet and the range into the training function and then create a new subset within the training function. The latter would require me to return the subset.

I'm going to go with the former approach as I think keeping the training function as simple as possible is beneficial. I'll try to handle all the dataset stuff in one place which will also keep things more organised.


## Conclusion, Notes of Importance and Plans

Fixed the memory issue. Started to figure out how to increase testing functionality, will create sub datasets etc.